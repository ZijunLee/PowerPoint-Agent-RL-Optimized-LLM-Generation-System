# RLTrainPPT - RL-based PPT Content Generation / åŸºäºå¼ºåŒ–å­¦ä¹ çš„PPTå†…å®¹ç”Ÿæˆ

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

[English](#english) | [ä¸­æ–‡è¯´æ˜](#chinese)

---

<a name="english"></a>

## ğŸŒŸ Introduction (English)

**RLTrainPPT** utilizes the **GSPO (Group Sequence Policy Optimization)** reinforcement learning method to fine-tune Large Language Models (LLMs). The project aims to automate the generation of high-quality, logically structured presentation outlines and detailed slide content.

## ğŸ“ Project Structure

```text
backend/
â”œâ”€â”€ .env                    # Environment config (API keys, model settings, etc.)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ README.md               # Documentation
â”‚
â”œâ”€â”€ outline/               # Phase 1: Outline Generation
â”‚   â”œâ”€â”€ prompt.py          # System prompts for outlines
â”‚   â”œâ”€â”€ train_trl.py       # GSPO training script for outlines
â”‚   â”œâ”€â”€ model_test.py      # Inference/Test script
â”‚   â”œâ”€â”€ topic.json         # Training dataset (topics)
â”‚   â”œâ”€â”€ outline.jsonl      # Generated outline results
â”‚   â””â”€â”€ output/            # Model checkpoints
â”‚
â””â”€â”€ content/               # Phase 2: Content Generation
    â”œâ”€â”€ prompt.py          # System prompts for content
    â”œâ”€â”€ train_trl.py       # GSPO training script for content
    â”œâ”€â”€ model_test.py      # Inference/Test script
    â”œâ”€â”€ content.jsonl      # Final generated content
    â””â”€â”€ output/            # Model checkpoints
